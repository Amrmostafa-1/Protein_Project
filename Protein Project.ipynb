{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e842a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8123b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q2/_chm3qg94gz5l7r736h39n040000gn/T/ipykernel_78040/1288919342.py:3: DtypeWarning: Columns (22,29,33,35,37,38,39,40,43,44,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_human = pd.read_table(\"uniprotkb_human.tsv\",delimiter='\\t')\n",
      "/var/folders/q2/_chm3qg94gz5l7r736h39n040000gn/T/ipykernel_78040/1288919342.py:4: DtypeWarning: Columns (22,29,33,35,37,38,39,40,41,43,44,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_rat = pd.read_table(\"uniprotkb_rat.tsv\",delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Get the tsv files as dataframe\n",
    "\n",
    "df_human = pd.read_table(\"uniprotkb_human.tsv\",delimiter='\\t')\n",
    "df_rat = pd.read_table(\"uniprotkb_rat.tsv\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2074fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry                                 0.000000\n",
       "Entry Name                            0.000000\n",
       "Protein names                         0.000000\n",
       "Gene Names                            0.207699\n",
       "Organism                              0.000000\n",
       "Length                                0.000000\n",
       "Sequence                              0.000000\n",
       "Involvement in disease                1.000000\n",
       "Pharmaceutical use                    1.000000\n",
       "Mutagenesis                           1.000000\n",
       "Disruption phenotype                  1.000000\n",
       "Biotechnological use                  1.000000\n",
       "Allergenic Properties                 1.000000\n",
       "Gene Ontology (biological process)    0.619481\n",
       "Gene Ontology (cellular component)    0.543190\n",
       "Gene Ontology (GO)                    0.418790\n",
       "Gene Ontology (molecular function)    0.664311\n",
       "Absorption                            1.000000\n",
       "Catalytic activity                    0.920414\n",
       "Cofactor                              0.957372\n",
       "DNA binding                           0.992416\n",
       "EC number                             0.916147\n",
       "Activity regulation                   0.999621\n",
       "Function [CC]                         0.902409\n",
       "Kinetics                              1.000000\n",
       "Pathway                               0.979489\n",
       "pH dependence                         1.000000\n",
       "Redox potential                       1.000000\n",
       "Rhea ID                               0.927901\n",
       "Site                                  0.998347\n",
       "Temperature dependence                1.000000\n",
       "Binding site                          0.969777\n",
       "Chain                                 0.886020\n",
       "Cross-link                            0.999856\n",
       "Disulfide bond                        0.988864\n",
       "Glycosylation                         0.999413\n",
       "Peptide                               1.000000\n",
       "Modified residue                      0.998640\n",
       "Lipidation                            0.999893\n",
       "Initiator methionine                  0.999925\n",
       "Post-translational modification       0.998944\n",
       "Propeptide                            1.000000\n",
       "Signal peptide                        0.886063\n",
       "Transit peptide                       0.999968\n",
       "Topological domain                    0.999904\n",
       "Transmembrane                         0.792610\n",
       "Subcellular location [CC]             0.761481\n",
       "Intramembrane                         0.999968\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human.isna().sum()/len(df_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f8a80",
   "metadata": {},
   "source": [
    "### All the steps done on the Human dataset will be repeated on the rat dataset (as the human features might be used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d698035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the empty columns and columns with mostly NaN\n",
    "df_human = df_human.drop(columns=['Entry','Entry Name','Involvement in disease',\n",
    "       'Pharmaceutical use','Mutagenesis','Disruption phenotype','Biotechnological use',\n",
    "       'Allergenic Properties','Absorption','Kinetics','pH dependence','Redox potential',\n",
    "       'Temperature dependence','Peptide','Propeptide','Catalytic activity', 'Cofactor',\n",
    "       'DNA binding', 'EC number', 'Activity regulation', 'Function [CC]',\n",
    "       'Pathway', 'Rhea ID', 'Site', 'Binding site', 'Chain', 'Cross-link',\n",
    "       'Disulfide bond', 'Glycosylation', 'Modified residue', 'Lipidation',\n",
    "       'Initiator methionine', 'Post-translational modification',\n",
    "       'Signal peptide', 'Transit peptide', 'Topological domain','Transmembrane','Intramembrane'])\n",
    "df_rat = df_rat.drop(columns=['Entry','Entry Name','Involvement in disease',\n",
    "       'Pharmaceutical use','Mutagenesis','Disruption phenotype','Biotechnological use',\n",
    "       'Allergenic Properties','Absorption','Kinetics','pH dependence','Redox potential',\n",
    "       'Temperature dependence','Peptide','Propeptide','Catalytic activity', 'Cofactor',\n",
    "       'DNA binding', 'EC number', 'Activity regulation', 'Function [CC]',\n",
    "       'Pathway', 'Rhea ID', 'Site', 'Binding site', 'Chain', 'Cross-link',\n",
    "       'Disulfide bond', 'Glycosylation', 'Modified residue', 'Lipidation',\n",
    "       'Initiator methionine', 'Post-translational modification',\n",
    "       'Signal peptide', 'Transit peptide', 'Topological domain','Transmembrane','Intramembrane'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f513ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_human['Gene Ontology (biological process)'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2408d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to keep only the first part of the Gene Ontology columns (only the part before the first [GO])\n",
    "\n",
    "# A regex pattern that captures everything until the first '[GO:'\n",
    "\n",
    "df_human['Gene Ontology (biological process)'] = df_human['Gene Ontology (biological process)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_human['Gene Ontology (cellular component)'] = df_human['Gene Ontology (cellular component)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_human['Gene Ontology (GO)'] = df_human['Gene Ontology (GO)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_human['Gene Ontology (molecular function)'] = df_human['Gene Ontology (molecular function)'].str.extract(r'^(.*?)(?=\\[GO:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c198e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rat['Gene Ontology (biological process)'] = df_rat['Gene Ontology (biological process)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_rat['Gene Ontology (cellular component)'] = df_rat['Gene Ontology (cellular component)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_rat['Gene Ontology (GO)'] = df_rat['Gene Ontology (GO)'].str.extract(r'^(.*?)(?=\\[GO:)')\n",
    "df_rat['Gene Ontology (molecular function)'] = df_rat['Gene Ontology (molecular function)'].str.extract(r'^(.*?)(?=\\[GO:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66584885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_human['Subcellular location [CC]'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5400419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to keep the subcelluar, could be used later for specifically predicting specific proteins\n",
    "\n",
    "# A regex pattern that captures everything between the SUBCELLULAR LOCATION:  and the first {ECO:\n",
    "\n",
    "df_human['Subcellular location [CC]'] = df_human['Subcellular location [CC]'].str.extract(r'(?<=SUBCELLULAR LOCATION: )(.*?)(?=\\s*{ECO:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4464732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rat['Subcellular location [CC]'] = df_rat['Subcellular location [CC]'].str.extract(r'(?<=SUBCELLULAR LOCATION: )(.*?)(?=\\s*{ECO:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab711cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Protein sequences over 500 length 23884\n",
      "Rat Protein sequences over 500 length 25999\n"
     ]
    }
   ],
   "source": [
    "print('Human Protein sequences over 500 length', len(df_human[df_human['Length']>500]))\n",
    "print('Rat Protein sequences over 500 length', len(df_rat[df_rat['Length']>500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52848a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decided to drop all the sequences that are above 500 aa in length (currently for the ease of modelling)\n",
    "# Then changed to 100 as the code wasn't running\n",
    "\n",
    "df_human = df_human[df_human['Length']<100]\n",
    "df_rat = df_rat[df_rat['Length']<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742328c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_human.shape)\n",
    "print(df_rat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb327fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human.isna().sum()/len(df_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45407e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rat.isna().sum()/len(df_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b097278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the NaN with unknown\n",
    "df_human = df_human.fillna('Unknown')\n",
    "df_rat = df_rat.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58366a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>187507.0</td>\n",
       "      <td>277.533479</td>\n",
       "      <td>366.827795</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>35991.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count        mean         std  min    25%    50%    75%      max\n",
       "Length  187507.0  277.533479  366.827795  7.0  109.0  181.0  347.0  35991.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "824627b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>84859.0</td>\n",
       "      <td>458.81659</td>\n",
       "      <td>527.151868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>35375.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count       mean         std  min    25%    50%    75%      max\n",
       "Length  84859.0  458.81659  527.151868  1.0  154.0  320.0  576.0  35375.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rat.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4301bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat both df for further analysis\n",
    "df = pd.concat((df_human,df_rat), axis=0).reset_index(drop=True)\n",
    "\n",
    "df.to_csv('Protein_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1779d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new dfs with only the Sequence and Organism columns to start the model.\n",
    "\n",
    "df_human_seq = df_human[['Sequence','Organism']]\n",
    "df_rat_seq = df_rat[['Sequence','Organism']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it easier to read change the Organism to Human or Rat respectivelly\n",
    "\n",
    "df_human_seq['Organism'] = df_human_seq['Organism'].replace(['Homo sapiens (Human)'], 'Human').astype('object')\n",
    "df_rat_seq['Organism'] = df_rat_seq['Organism'].replace(['Rattus norvegicus (Rat)'], 'Rat').astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ed987",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9739b0",
   "metadata": {},
   "source": [
    "### Concat both df by row to continue workin with the resulting df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seq = pd.concat((df_human_seq, df_rat_seq), axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9eedad",
   "metadata": {},
   "source": [
    "#### Take a fraction of the sample as the models were not running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67893ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df_seq.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a9c51",
   "metadata": {},
   "source": [
    "## Tokenize the Protein Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd59820",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['Token_Sequence'] = sample_df['Sequence'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90119b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GlobalMaxPooling1D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8c1ef",
   "metadata": {},
   "source": [
    "## RNN Model (LSTM) Classifier\n",
    "Predict wether a protein sequence is human or rat protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequences to integer tokens\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sample_df['Token_Sequence'].apply(lambda x: ''.join(x)))\n",
    "X = tokenizer.texts_to_sequences(sample_df['Token_Sequence'].apply(lambda x: ''.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e065b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to have the same length\n",
    "X = pad_sequences(X, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Human' and 'Rat' to integers\n",
    "\n",
    "y = sample_df['Organism'].map({'Human': 0, 'Rat': 1}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ba634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=10))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcbbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fef9d0",
   "metadata": {},
   "source": [
    "- Could also optimize for recall or precision to improve the model depending on the critical outcome.\n",
    "- F1 score could be a good way to optmize the model, not natively supported has to be manually calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0652547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels, with a threshold of 0.5 anything higher will be considered \"Rat\" and lower will be considered \"Human\"\n",
    "predicted_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Compare predicted labels with the actual labels\n",
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predicted_labels})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790002cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b1808",
   "metadata": {},
   "source": [
    "#### Tested model parameters to optimize the model\n",
    "- Model with intial parameters (unidirectional LSTM, LSTM = 50, epochs=10)    \n",
    "    - Test Loss: 0.4611\n",
    "    - Test Accuracy: 0.7674\n",
    "    - Test Precision: 0.7213\n",
    "    - Test Recall: 0.1624"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19a102",
   "metadata": {},
   "source": [
    "- Model parameters (bidirectional LSTM, LSTM = 50, epochs=10)    \n",
    "    - Test Loss: 0.4431\n",
    "    - Test Accuracy: 0.7731\n",
    "    - Test Precision: 0.6204\n",
    "    - Test Recall: 0.3137\n",
    "- switching to biderectional LSTM (gets sequence patterns from beginning and end) improved the model accuracy and recall but the precision decreased\n",
    "- This model has the lowest loss (crossentropy), which should be the best metric to evaluate the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3795bf",
   "metadata": {},
   "source": [
    "- Model parameters (bidirectional LSTM, LSTM = 100, epochs=10)  \n",
    "\n",
    "    - Test Loss: 0.4629\n",
    "    - Test Accuracy: 0.7464\n",
    "    - Test Precision: 0.5397\n",
    "    - Test Recall: 0.1255\n",
    "    \n",
    "- LSTM 100 decread all the test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd137a5e",
   "metadata": {},
   "source": [
    "- Model parameters (bidirectional LSTM, LSTM = 50, epochs=20)  \n",
    "    \n",
    "    - Test Loss: 0.4554\n",
    "    - Test Accuracy: 0.7712\n",
    "    - Test Precision: 0.5544\n",
    "    - Test Recall: 0.5830\n",
    "    \n",
    "- Reverting to LSTM 50 and increasing the epochs to 20 incread the recall score and decreased the precision score. The accuracy is almost unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b39d01",
   "metadata": {},
   "source": [
    "## RNN Model (LSTM)\n",
    "Predict new protein sequences not seen in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(sample_df['Token_Sequence'].apply(lambda x: ''.join(x)))\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for sequence in sample_df['Token_Sequence']:\n",
    "    token_sequence = tokenizer.texts_to_sequences([sequence])[0]\n",
    "    for i in range(1, len(token_sequence)):\n",
    "        n_gram_sequence = token_sequence[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences and split input and output\n",
    "input_sequences = pad_sequences(input_sequences)\n",
    "X, y = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=50, input_length=X.shape[1]))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aac423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, tokenizer, max_length, init_seq=None, ):\n",
    "    if init_seq is None:\n",
    "        # Starting with a random amino acid token. Alternatively, choose a fixed start like \"M\".\n",
    "        init_seq = np.random.choice(list(tokenizer.word_index.keys()))\n",
    "    \n",
    "    new_sequence = init_seq\n",
    "    for _ in range(max_length):\n",
    "        token_sequence = tokenizer.texts_to_sequences([new_sequence])[0]\n",
    "        token_sequence = pad_sequences([token_sequence], maxlen=X.shape[1], padding='pre')\n",
    "        predicted_token = np.argmax(model.predict(token_sequence), axis=-1)\n",
    "        predicted_amino_acid = tokenizer.index_word[predicted_token[0]]\n",
    "        new_sequence += predicted_amino_acid\n",
    "    return new_sequence.upper()\n",
    "\n",
    "# Generate a new sequence of length desired length\n",
    "generated_sequence = generate_sequence(model, tokenizer, 100)\n",
    "\n",
    "\n",
    "# Print the generated sequence\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_seq = generated_sequence in sample_df['Sequence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the generated sequences in a txt file if they are new and not in the df.\n",
    "\n",
    "if generated_sequence not in sample_df['Sequence'].values:\n",
    "    with open('Generated Sequences.txt', 'a') as file:\n",
    "        file.write(generated_sequence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the generated sequence through the first model to predict wether this sequence is Human or Rat protein sequence\n",
    "\n",
    "tokenized_sequence = tokenizer.texts_to_sequences([generated_sequence])\n",
    "new_sequence = pad_sequences(tokenized_sequence, maxlen=100, padding='post')\n",
    "\n",
    "# 2. Use the model to predict\n",
    "prediction = model.predict(new_sequence)\n",
    "\n",
    "# 3. Interpret the prediction\n",
    "if prediction >= 0.5:\n",
    "    print(\"The sequence is predicted to be Human.\")\n",
    "else:\n",
    "    print(\"The sequence is predicted to be Rat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c805737",
   "metadata": {},
   "source": [
    "## API for PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a743a0",
   "metadata": {},
   "source": [
    "Use PDB API to check if the generated protein sequence excists in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58545aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# Construct the query\n",
    "query_json = {\n",
    "  \"query\": {\n",
    "    \"type\": \"terminal\",\n",
    "    \"service\": \"sequence\",\n",
    "    \"parameters\": {\n",
    "      \"evalue_cutoff\": 1,\n",
    "      \"identity_cutoff\": 0.9,\n",
    "      \"sequence_type\": \"protein\",\n",
    "      \"value\": generated_sequence\n",
    "    }\n",
    "  },\n",
    "  \"request_options\": {\n",
    "    \"scoring_strategy\": \"sequence\"\n",
    "  },\n",
    "  \"return_type\": \"polymer_entity\"\n",
    "}\n",
    "\n",
    "# Define the endpoint\n",
    "url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
    "\n",
    "# Make the API request\n",
    "response = requests.post(url, json=query_json)\n",
    "\n",
    "# Check if the request was successful\n",
    "print(response.status_code)\n",
    "match = response.json()\n",
    "print(match['result_set'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f8be7",
   "metadata": {},
   "source": [
    "This gives all the proteins that have this sequence in nature.\n",
    "- Score of 1 means it the generated sequence matches exactly a protein or part of a protein.\n",
    "- Scores less than 1 means that the bulk of the sequences matches but there are mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f7034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "match_df = pd.DataFrame(match['result_set'])\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.to_csv('Protein match.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdda69b",
   "metadata": {},
   "source": [
    "This could used as metric to evaluate the model, as it is trained only a portion of all available proteins.\\\n",
    "If it produces proteins that are available in nature consistently, it could be an indication that the model understands the relationship of protein sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd01a99",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb39b0a",
   "metadata": {},
   "source": [
    "(H0): The mean length of human sequences is equal to the mean length of rat sequences.\n",
    "\n",
    " \n",
    "(H1): The mean length of human sequences is not equal to the mean length of rat sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(df_human['Length'], df_rat['Length'], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd47572",
   "metadata": {},
   "source": [
    "- Since the pvalue is 0 (Probably rounded to 0) this means we reject the H0, which is that the mean length of human sequences is equal to the mean length of rat sequences.\n",
    "- This shows that there is a statistically significant difference between the mean length of human and rat sequences, and since the statistic is below 0 this means that the mean length of sequences for humans is shorter than that for rats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96f498",
   "metadata": {},
   "source": [
    "## Testing ProtBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5c172",
   "metadata": {},
   "source": [
    "Using ProtBERT to predict features, as this could help identify the possible theraputical or specific protein functions the new generated protein sequence could have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745741b1",
   "metadata": {},
   "source": [
    "https://huggingface.co/Rostlab/prot_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import re\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "sequence_Example = \"nylfqgrqecyafngtqrfleryiynreefarfdsdvgefravtelgrpaa\"\n",
    "sequence_Example.upper()\n",
    "sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n",
    "encoded_input = tokenizer(sequence_Example, return_tensors='pt')\n",
    "output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ada1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
